{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734f616b2ce12d96",
   "metadata": {},
   "source": [
    "First we started by reading the csv file 'captions.txt' and then displaying the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "id": "a2ec57dd80d3b095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T15:50:24.804789Z",
     "start_time": "2026-01-06T15:50:24.420Z"
    }
   },
   "source": [
    "\n",
    "from os import truncate\n",
    "\n",
    "import pandas as pd\n",
    "from keras import Layer\n",
    "from tensorflow.python.keras import Sequential\n",
    "\n",
    "captions_path = \"../data/captions/captions.txt\"\n",
    "\n",
    "df = pd.read_csv(captions_path)\n",
    "print(df.head())\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0  A child in a pink dress is climbing up a set o...  \n",
      "1              A girl going into a wooden building .  \n",
      "2   A little girl climbing into a wooden playhouse .  \n",
      "3  A little girl climbing the stairs to her playh...  \n",
      "4  A little girl in a pink dress going into a woo...  \n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "36954f9ffb154131",
   "metadata": {},
   "source": [
    "Now we want group all rows that have the same image filename together, keeping only the caption column, then for each group we convert all captions into a python list, and finally convert the pandas object into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "id": "2557e48b7d4c085e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T15:50:27.978531Z",
     "start_time": "2026-01-06T15:50:27.643701Z"
    }
   },
   "source": [
    "image_to_captions = (\n",
    "    df.groupby('image')['caption'].apply(list).to_dict()\n",
    ")\n",
    "\n",
    "print(\"Number of images: \", len(image_to_captions))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  8091\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "d5c12225db9af930",
   "metadata": {},
   "source": [
    "Creating a new column for captions in lower case and without punctuation"
   ]
  },
  {
   "cell_type": "code",
   "id": "18b4f84460878908",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T15:50:30.300498Z",
     "start_time": "2026-01-06T15:50:30.046256Z"
    }
   },
   "source": [
    "\n",
    "import string\n",
    "\n",
    "#Removing the upper cases\n",
    "df['lower_caption'] = df['caption'].str.lower()\n",
    "\n",
    "#Function to remove the punctuation\n",
    "def remove_punctuation(lower_caption):\n",
    "    for char in string.punctuation:\n",
    "        lower_caption = lower_caption.replace(char, '')\n",
    "    return lower_caption\n",
    "\n",
    "df['lower_caption'] = df['lower_caption'].apply(remove_punctuation)\n",
    "\n",
    "#Comparing the new column with the old column\n",
    "df.sample(10)\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           image  \\\n",
       "30876  3541915243_956c1aa8ef.jpg   \n",
       "4250   2043520315_4a2c782c90.jpg   \n",
       "15020  2815745115_c8479d560c.jpg   \n",
       "28079   343218198_1ca90e0734.jpg   \n",
       "22408  3205336477_037d4b6bd9.jpg   \n",
       "26788  3378553508_e37e281d25.jpg   \n",
       "416    1095590286_c654f7e5a9.jpg   \n",
       "6689   2256138896_3e24b0b28d.jpg   \n",
       "8594   2396669903_5217a83641.jpg   \n",
       "39756   825918657_d92f1761f4.jpg   \n",
       "\n",
       "                                                 caption  \\\n",
       "30876                                 Asian spectators .   \n",
       "4250   A group of hikers led by a black and white dog...   \n",
       "15020  A carnival worker surrounded by stuffed animals .   \n",
       "28079  a black great Dane running toward the camera i...   \n",
       "22408                     Two men wrestling at a match .   \n",
       "26788  Several people are looking out from a building...   \n",
       "416                           a dog chases another dog .   \n",
       "6689   A rock climber with a white helmet is repelling .   \n",
       "8594   Sombody has stuck the face of Groucho Marx on ...   \n",
       "39756  A brown and white dog with a pink Frisbee in i...   \n",
       "\n",
       "                                           lower_caption  \n",
       "30876                                  asian spectators   \n",
       "4250   a group of hikers led by a black and white dog...  \n",
       "15020   a carnival worker surrounded by stuffed animals   \n",
       "28079  a black great dane running toward the camera i...  \n",
       "22408                      two men wrestling at a match   \n",
       "26788  several people are looking out from a building...  \n",
       "416                            a dog chases another dog   \n",
       "6689    a rock climber with a white helmet is repelling   \n",
       "8594   sombody has stuck the face of groucho marx on ...  \n",
       "39756  a brown and white dog with a pink frisbee in i...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>lower_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30876</th>\n",
       "      <td>3541915243_956c1aa8ef.jpg</td>\n",
       "      <td>Asian spectators .</td>\n",
       "      <td>asian spectators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4250</th>\n",
       "      <td>2043520315_4a2c782c90.jpg</td>\n",
       "      <td>A group of hikers led by a black and white dog...</td>\n",
       "      <td>a group of hikers led by a black and white dog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15020</th>\n",
       "      <td>2815745115_c8479d560c.jpg</td>\n",
       "      <td>A carnival worker surrounded by stuffed animals .</td>\n",
       "      <td>a carnival worker surrounded by stuffed animals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28079</th>\n",
       "      <td>343218198_1ca90e0734.jpg</td>\n",
       "      <td>a black great Dane running toward the camera i...</td>\n",
       "      <td>a black great dane running toward the camera i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22408</th>\n",
       "      <td>3205336477_037d4b6bd9.jpg</td>\n",
       "      <td>Two men wrestling at a match .</td>\n",
       "      <td>two men wrestling at a match</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26788</th>\n",
       "      <td>3378553508_e37e281d25.jpg</td>\n",
       "      <td>Several people are looking out from a building...</td>\n",
       "      <td>several people are looking out from a building...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1095590286_c654f7e5a9.jpg</td>\n",
       "      <td>a dog chases another dog .</td>\n",
       "      <td>a dog chases another dog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>2256138896_3e24b0b28d.jpg</td>\n",
       "      <td>A rock climber with a white helmet is repelling .</td>\n",
       "      <td>a rock climber with a white helmet is repelling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8594</th>\n",
       "      <td>2396669903_5217a83641.jpg</td>\n",
       "      <td>Sombody has stuck the face of Groucho Marx on ...</td>\n",
       "      <td>sombody has stuck the face of groucho marx on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39756</th>\n",
       "      <td>825918657_d92f1761f4.jpg</td>\n",
       "      <td>A brown and white dog with a pink Frisbee in i...</td>\n",
       "      <td>a brown and white dog with a pink frisbee in i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "816fb7649f6a97ab",
   "metadata": {},
   "source": [
    "Tokenization for each caption"
   ]
  },
  {
   "cell_type": "code",
   "id": "18d1f4ed949c4312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T15:50:35.394744Z",
     "start_time": "2026-01-06T15:50:33.270408Z"
    }
   },
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#Was having trouble with the import word_tokenize so had to add the line below\n",
    "#nltk.download('punkt_tab')\n",
    "\n",
    "#Creating a new column for tokens for each caption\n",
    "df['tokens'] = df['lower_caption'].apply(lambda x: word_tokenize(x))\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       image  \\\n",
       "0  1000268201_693b08cb0e.jpg   \n",
       "1  1000268201_693b08cb0e.jpg   \n",
       "2  1000268201_693b08cb0e.jpg   \n",
       "3  1000268201_693b08cb0e.jpg   \n",
       "4  1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \\\n",
       "0  A child in a pink dress is climbing up a set o...   \n",
       "1              A girl going into a wooden building .   \n",
       "2   A little girl climbing into a wooden playhouse .   \n",
       "3  A little girl climbing the stairs to her playh...   \n",
       "4  A little girl in a pink dress going into a woo...   \n",
       "\n",
       "                                       lower_caption  \\\n",
       "0  a child in a pink dress is climbing up a set o...   \n",
       "1               a girl going into a wooden building    \n",
       "2    a little girl climbing into a wooden playhouse    \n",
       "3  a little girl climbing the stairs to her playh...   \n",
       "4  a little girl in a pink dress going into a woo...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [a, child, in, a, pink, dress, is, climbing, u...  \n",
       "1        [a, girl, going, into, a, wooden, building]  \n",
       "2  [a, little, girl, climbing, into, a, wooden, p...  \n",
       "3  [a, little, girl, climbing, the, stairs, to, h...  \n",
       "4  [a, little, girl, in, a, pink, dress, going, i...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>lower_caption</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "      <td>a child in a pink dress is climbing up a set o...</td>\n",
       "      <td>[a, child, in, a, pink, dress, is, climbing, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "      <td>a girl going into a wooden building</td>\n",
       "      <td>[a, girl, going, into, a, wooden, building]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "      <td>a little girl climbing into a wooden playhouse</td>\n",
       "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "      <td>a little girl climbing the stairs to her playh...</td>\n",
       "      <td>[a, little, girl, climbing, the, stairs, to, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "      <td>a little girl in a pink dress going into a woo...</td>\n",
       "      <td>[a, little, girl, in, a, pink, dress, going, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "85c2f492de7cb076",
   "metadata": {},
   "source": [
    "Building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "id": "f5ab89e550207c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T15:54:39.287759Z",
     "start_time": "2026-01-06T15:54:39.178669Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "\n",
    "#Couting all the words\n",
    "word_counter = Counter()\n",
    "\n",
    "for i in df['tokens']:\n",
    "    word_counter.update(i)\n",
    "\n",
    "#Defining special tokens\n",
    "#To fill empty positions\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "#When a word is not in the vocabulary\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "#Start for inference\n",
    "START_TOKEN = \"<START>\"\n",
    "#End for inference\n",
    "END_TOKEN = \"<END>\"\n",
    "\n",
    "#Creating a vocabulary\n",
    "word_to_idx = {\n",
    "    PAD_TOKEN: 0,\n",
    "    UNK_TOKEN: 1,\n",
    "    START_TOKEN: 2,\n",
    "    END_TOKEN: 3\n",
    "}\n",
    "\n",
    "for word in word_counter:\n",
    "    #Auto increments the ID generator\n",
    "    word_to_idx[word] = len(word_to_idx)\n",
    "\n",
    "\n",
    "print(\"Vocabulary size:\", len(word_to_idx))\n",
    "print(\"Sample entries:\", list(word_to_idx.items())[:10])\n",
    "print(\"last entry\", list(word_to_idx.items())[-1])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8831\n",
      "Sample entries: [('<PAD>', 0), ('<UNK>', 1), ('<START>', 2), ('<END>', 3), ('a', 4), ('child', 5), ('in', 6), ('pink', 7), ('dress', 8), ('is', 9)]\n",
      "last entry ('patterns', 8830)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "7af2203e9e98d4c",
   "metadata": {},
   "source": [
    "Convert the tokens to integers\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "d4443c9befb13be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T15:56:52.434033Z",
     "start_time": "2026-01-06T15:56:52.252301Z"
    }
   },
   "source": [
    "\n",
    "#Creating a variable for unk token index\n",
    "UNK_IDX = word_to_idx[UNK_TOKEN]\n",
    "\n",
    "sequence = []\n",
    "\n",
    "#For loop to check if the word is in the tokens dataframe; if it is just adds the index; if it's not it will add the unk index\n",
    "for tokens in df['tokens']:\n",
    "    seq = []\n",
    "    for word in tokens:\n",
    "        if word in word_to_idx:\n",
    "            seq.append(word_to_idx[word])\n",
    "        else:\n",
    "            seq.append(UNK_IDX)\n",
    "    #Appending to the empty sequence list\n",
    "    sequence.append(seq)\n",
    "\n",
    "print(\"Original: \", df['tokens'][1])\n",
    "print(\"Sequence: \", sequence[1])\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['a', 'girl', 'going', 'into', 'a', 'wooden', 'building']\n",
      "Sequence:  [4, 18, 19, 20, 4, 21, 22]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "d93adb039d3f52f0",
   "metadata": {},
   "source": [
    "Organizing"
   ]
  },
  {
   "cell_type": "code",
   "id": "db0b27e6f5175313",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T15:56:58.587890Z",
     "start_time": "2026-01-06T15:56:58.565998Z"
    }
   },
   "source": [
    "\n",
    "#Dropping caption, and lower_caption columns to organize the dataframe since they aren't useful anymore\n",
    "#Inplace = True to change the original and don't give us just a copy\n",
    "df.drop(['caption', 'lower_caption'], axis= 'columns', inplace= True)\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "88e4d1da6665dd4e",
   "metadata": {},
   "source": [
    "Sequence padding and truncating\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "ce628a63e60a5910",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T15:57:25.314915Z",
     "start_time": "2026-01-06T15:57:25.132487Z"
    }
   },
   "source": [
    "\n",
    "#Checking the biggest sequence and the 95%\n",
    "import numpy as np\n",
    "lengths = [len(i) for i in sequence]\n",
    "print(f\"Max: {max(lengths)}, 95th percentile: {np.percentile(lengths, 95)}\")\n",
    "\n",
    "#Truncating sequences > 20\n",
    "#Padding sequences < 20\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Because we just added <START> and <END>\n",
    "max_length = 22\n",
    "\n",
    "padded_sequences = pad_sequences(\n",
    "    sequence,\n",
    "    maxlen = max_length,\n",
    "    #Padding at the end\n",
    "    padding = 'post',\n",
    "    #Truncating at the end\n",
    "    truncating = 'post'\n",
    ")\n",
    "\n",
    "#Printing the first 20 sequences as numpy arrays\n",
    "print(padded_sequences[:20])\n",
    "print(padded_sequences.shape)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 36, 95th percentile: 18.0\n",
      "[[ 4  5  6  4  7  8  9 10 11  4 12 13 14  6 15 16 17  0  0  0  0  0]\n",
      " [ 4 18 19 20  4 21 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 23 18 10 20  4 21 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 23 18 10 25 14 26 27 24  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 23 18  6  4  7  8 19 20  4 21 28  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 29 30 31  4 32 30 33 34  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 29 30 31  4 35 30 36 37 38 39 40 25 41  0  0  0  0  0  0  0  0]\n",
      " [ 4 29 30 31  4 42 30 37 43 44 33 45 46 38 39  6 25 47  0  0  0  0]\n",
      " [48 49 13 50 51 52 46 38 39 40 25 41  0  0  0  0  0  0  0  0  0  0]\n",
      " [48 49 40 53 54 55 38 39  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 23 18 56  6 57 58  6 59 13  4 60 61 37 27 62  6  4 63  0  0  0]\n",
      " [ 4 23 18  9 64  6 59 13  4 65 60 61  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 66 18  6 25 67 68 37 69  6 59 13  4 42 70 37  4 61 40 71  0  0]\n",
      " [72  9  4 18 37 73 64  6 59 13  4 61 74  0  0  0  0  0  0  0  0  0]\n",
      " [75 18 37 73 74 76  6 25 67  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 77 78 40  4 79 80 81 30 58 82 83  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 77 78 40 25 79 26 84  4 42 30  9 85 86  0  0  0  0  0  0  0  0]\n",
      " [ 4 77 87 40  4 79 76 37  4 42 31 29 30 64 88 26 83  0  0  0  0  0]\n",
      " [ 4 89 77 90 40  4 91 79 37 81 30  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [77 92 40 79 93 94 13 30 64 40 95  0  0  0  0  0  0  0  0  0  0  0]]\n",
      "(40455, 22)\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "e13120cae151f6d1",
   "metadata": {},
   "source": [
    "Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "id": "845fed4899a7debf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T15:57:32.010246Z",
     "start_time": "2026-01-06T15:57:31.381758Z"
    }
   },
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "\n",
    "#To check the size and length\n",
    "print(f\"Size of the vocabulary: {len(word_to_idx)}\")\n",
    "print(f\"Length of each sequence: {padded_sequences.shape}\")\n",
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "#Default dimension for small / medium datasets (flickr8k)\n",
    "embedding_dim = 128\n",
    "input_length = 20\n",
    "\n",
    "#Building the model\n",
    "model = models.Sequential([\n",
    "    Embedding(input_dim = vocab_size, output_dim = embedding_dim, input_length = input_length), LSTM(256) #Standard default\n",
    "])\n",
    "\n",
    "model.build(input_shape=(None, input_length))\n",
    "model.summary()\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary: 8831\n",
      "Length of each sequence: (40455, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diogo\\Desktop\\Multi-Modal Classification and Analysis of Images and Text using Deep Learning\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │     \u001B[38;5;34m1,130,368\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │       \u001B[38;5;34m394,240\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,130,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,524,608\u001B[0m (5.82 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,524,608</span> (5.82 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,524,608\u001B[0m (5.82 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,524,608</span> (5.82 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "df8dc56f3117d94",
   "metadata": {},
   "source": [
    "Aligning images with captions"
   ]
  },
  {
   "cell_type": "code",
   "id": "5105adabe0ccdef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-06T15:57:41.343478Z",
     "start_time": "2026-01-06T15:57:39.687088Z"
    }
   },
   "source": [
    "\n",
    "import os\n",
    "\n",
    "#list to store the image path\n",
    "image_paths = []\n",
    "#list to store the tokenized sequence\n",
    "caption_sequences = []\n",
    "\n",
    "IMAGE_DIR = \"../data/images/flickr8k_images/images\"\n",
    "\n",
    "#Looping over rows not images\n",
    "for i in range(len(df)):\n",
    "    #selecting the image file name for the i caption\n",
    "    image_filename = df.iloc[i]['image']\n",
    "    #building  a path so the model can find the image\n",
    "    image_path = os.path.join(IMAGE_DIR, image_filename)\n",
    "\n",
    "    #Adding to the lists image_path per caption\n",
    "    image_paths.append(image_path)\n",
    "    #the padded sequence of that same caption\n",
    "    caption_sequences.append(padded_sequences[i])\n",
    "\n",
    "print(len(image_paths))\n",
    "print(len(caption_sequences))\n",
    "\n",
    "#testing\n",
    "idx = 5\n",
    "print(image_paths[idx])\n",
    "print(caption_sequences[idx])\n",
    "print(df.iloc[idx])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40455\n",
      "40455\n",
      "../data/images/flickr8k_images/images\\1001773457_577c3a7d70.jpg\n",
      "[ 4 29 30 31  4 32 30 33 34  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "image                             1001773457_577c3a7d70.jpg\n",
      "tokens    [a, black, dog, and, a, spotted, dog, are, fig...\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
