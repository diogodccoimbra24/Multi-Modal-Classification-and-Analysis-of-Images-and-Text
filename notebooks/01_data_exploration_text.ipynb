{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First we started by reading the csv file 'captions.txt' and then displaying the first five rows",
   "id": "734f616b2ce12d96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:22:27.588622Z",
     "start_time": "2026-01-05T21:22:22.301632Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from os import truncate\n",
    "\n",
    "import pandas as pd\n",
    "from keras import Layer\n",
    "from tensorflow.python.keras import Sequential\n",
    "\n",
    "captions_path = \"../data/captions/captions.txt\"\n",
    "\n",
    "df = pd.read_csv(captions_path)\n",
    "print(df.head())\n"
   ],
   "id": "a2ec57dd80d3b095",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0  A child in a pink dress is climbing up a set o...  \n",
      "1              A girl going into a wooden building .  \n",
      "2   A little girl climbing into a wooden playhouse .  \n",
      "3  A little girl climbing the stairs to her playh...  \n",
      "4  A little girl in a pink dress going into a woo...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diogo\\Desktop\\Multi-Modal Classification and Analysis of Images and Text using Deep Learning\\.venv\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we want group all rows that have the same image filename together, keeping only the caption column, then for each group we convert all captions into a python list, and finally convert the pandas object into a dictionary",
   "id": "36954f9ffb154131"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:22:27.745149Z",
     "start_time": "2026-01-05T21:22:27.625624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_to_captions = (\n",
    "    df.groupby('image')['caption'].apply(list).to_dict()\n",
    ")\n",
    "\n",
    "print(\"Number of images: \", len(image_to_captions))"
   ],
   "id": "2557e48b7d4c085e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  8091\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating a new column for captions in lower case and without punctuation",
   "id": "d5c12225db9af930"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:22:27.906834Z",
     "start_time": "2026-01-05T21:22:27.773814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import string\n",
    "\n",
    "#Removing the upper cases\n",
    "df['lower_caption'] = df['caption'].str.lower()\n",
    "\n",
    "#Function to remove the punctuation\n",
    "def remove_punctuation(lower_caption):\n",
    "    for char in string.punctuation:\n",
    "        lower_caption = lower_caption.replace(char, '')\n",
    "    return lower_caption\n",
    "\n",
    "df['lower_caption'] = df['lower_caption'].apply(remove_punctuation)\n",
    "\n",
    "#Comparing the new column with the old column\n",
    "df.sample(10)\n",
    "\n"
   ],
   "id": "18b4f84460878908",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           image  \\\n",
       "13444   269898095_d00ac7d7a4.jpg   \n",
       "4822   2088910854_c6f8d4f5f9.jpg   \n",
       "4813   2088460083_42ee8a595a.jpg   \n",
       "10287  2484190118_e89363c465.jpg   \n",
       "15156  2827964381_408a310809.jpg   \n",
       "19102  3046286572_d2050ab0d9.jpg   \n",
       "16915  2921112724_5cb85d7413.jpg   \n",
       "7615   2318659263_c24005a5cb.jpg   \n",
       "23273  3240094420_a9eea11d39.jpg   \n",
       "3743   1819261140_6c022f4b1d.jpg   \n",
       "\n",
       "                                                 caption  \\\n",
       "13444              Two people sit on a bench at a park .   \n",
       "4822   A man wearing a black knit cap with a red and ...   \n",
       "4813            An old , beat-up jeep being towed away .   \n",
       "10287  A small boy stands on a cement stump in a park...   \n",
       "15156  Two dogs are jumping up at each other in a gra...   \n",
       "19102  A man in a brown shirt and jeans is doing a tr...   \n",
       "16915  A man riding a three wheeled vehicle topples o...   \n",
       "7615        A fluffy white dog running across the snow .   \n",
       "23273                  Four women , two with id badges .   \n",
       "3743   a man sitting at a table with a scary mask cov...   \n",
       "\n",
       "                                           lower_caption  \n",
       "13444               two people sit on a bench at a park   \n",
       "4822   a man wearing a black knit cap with a red and ...  \n",
       "4813               an old  beatup jeep being towed away   \n",
       "10287  a small boy stands on a cement stump in a park...  \n",
       "15156  two dogs are jumping up at each other in a gra...  \n",
       "19102  a man in a brown shirt and jeans is doing a tr...  \n",
       "16915  a man riding a three wheeled vehicle topples o...  \n",
       "7615         a fluffy white dog running across the snow   \n",
       "23273                    four women  two with id badges   \n",
       "3743   a man sitting at a table with a scary mask cov...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>lower_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13444</th>\n",
       "      <td>269898095_d00ac7d7a4.jpg</td>\n",
       "      <td>Two people sit on a bench at a park .</td>\n",
       "      <td>two people sit on a bench at a park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4822</th>\n",
       "      <td>2088910854_c6f8d4f5f9.jpg</td>\n",
       "      <td>A man wearing a black knit cap with a red and ...</td>\n",
       "      <td>a man wearing a black knit cap with a red and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4813</th>\n",
       "      <td>2088460083_42ee8a595a.jpg</td>\n",
       "      <td>An old , beat-up jeep being towed away .</td>\n",
       "      <td>an old  beatup jeep being towed away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10287</th>\n",
       "      <td>2484190118_e89363c465.jpg</td>\n",
       "      <td>A small boy stands on a cement stump in a park...</td>\n",
       "      <td>a small boy stands on a cement stump in a park...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15156</th>\n",
       "      <td>2827964381_408a310809.jpg</td>\n",
       "      <td>Two dogs are jumping up at each other in a gra...</td>\n",
       "      <td>two dogs are jumping up at each other in a gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19102</th>\n",
       "      <td>3046286572_d2050ab0d9.jpg</td>\n",
       "      <td>A man in a brown shirt and jeans is doing a tr...</td>\n",
       "      <td>a man in a brown shirt and jeans is doing a tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16915</th>\n",
       "      <td>2921112724_5cb85d7413.jpg</td>\n",
       "      <td>A man riding a three wheeled vehicle topples o...</td>\n",
       "      <td>a man riding a three wheeled vehicle topples o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7615</th>\n",
       "      <td>2318659263_c24005a5cb.jpg</td>\n",
       "      <td>A fluffy white dog running across the snow .</td>\n",
       "      <td>a fluffy white dog running across the snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23273</th>\n",
       "      <td>3240094420_a9eea11d39.jpg</td>\n",
       "      <td>Four women , two with id badges .</td>\n",
       "      <td>four women  two with id badges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3743</th>\n",
       "      <td>1819261140_6c022f4b1d.jpg</td>\n",
       "      <td>a man sitting at a table with a scary mask cov...</td>\n",
       "      <td>a man sitting at a table with a scary mask cov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tokenization for each caption",
   "id": "816fb7649f6a97ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:22:29.657007Z",
     "start_time": "2026-01-05T21:22:27.922345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#Was having trouble with the import word_tokenize so had to add the line below\n",
    "#nltk.download('punkt_tab')\n",
    "\n",
    "#Creating a new column for tokens for each caption\n",
    "df['tokens'] = df['lower_caption'].apply(lambda x: word_tokenize(x))\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "18d1f4ed949c4312",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       image  \\\n",
       "0  1000268201_693b08cb0e.jpg   \n",
       "1  1000268201_693b08cb0e.jpg   \n",
       "2  1000268201_693b08cb0e.jpg   \n",
       "3  1000268201_693b08cb0e.jpg   \n",
       "4  1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \\\n",
       "0  A child in a pink dress is climbing up a set o...   \n",
       "1              A girl going into a wooden building .   \n",
       "2   A little girl climbing into a wooden playhouse .   \n",
       "3  A little girl climbing the stairs to her playh...   \n",
       "4  A little girl in a pink dress going into a woo...   \n",
       "\n",
       "                                       lower_caption  \\\n",
       "0  a child in a pink dress is climbing up a set o...   \n",
       "1               a girl going into a wooden building    \n",
       "2    a little girl climbing into a wooden playhouse    \n",
       "3  a little girl climbing the stairs to her playh...   \n",
       "4  a little girl in a pink dress going into a woo...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [a, child, in, a, pink, dress, is, climbing, u...  \n",
       "1        [a, girl, going, into, a, wooden, building]  \n",
       "2  [a, little, girl, climbing, into, a, wooden, p...  \n",
       "3  [a, little, girl, climbing, the, stairs, to, h...  \n",
       "4  [a, little, girl, in, a, pink, dress, going, i...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>lower_caption</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "      <td>a child in a pink dress is climbing up a set o...</td>\n",
       "      <td>[a, child, in, a, pink, dress, is, climbing, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "      <td>a girl going into a wooden building</td>\n",
       "      <td>[a, girl, going, into, a, wooden, building]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "      <td>a little girl climbing into a wooden playhouse</td>\n",
       "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "      <td>a little girl climbing the stairs to her playh...</td>\n",
       "      <td>[a, little, girl, climbing, the, stairs, to, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "      <td>a little girl in a pink dress going into a woo...</td>\n",
       "      <td>[a, little, girl, in, a, pink, dress, going, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Building the vocabulary",
   "id": "85c2f492de7cb076"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:22:29.750395Z",
     "start_time": "2026-01-05T21:22:29.673086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "#Couting all the words\n",
    "word_counter = Counter()\n",
    "\n",
    "for i in df['tokens']:\n",
    "    word_counter.update(i)\n",
    "\n",
    "#Defining special tokens\n",
    "#To fill empty positions\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "#When a word is not in the vocabulary\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "#Creating a vocabulary\n",
    "word_to_idx = {\n",
    "    PAD_TOKEN: 0,\n",
    "    UNK_TOKEN: 1\n",
    "}\n",
    "\n",
    "for word in word_counter:\n",
    "    #Auto increments the ID generator\n",
    "    word_to_idx[word] = len(word_to_idx)\n",
    "\n",
    "\n",
    "print(\"Vocabulary size:\", len(word_to_idx))\n",
    "print(\"Sample entries:\", list(word_to_idx.items())[:10])\n"
   ],
   "id": "f5ab89e550207c45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8829\n",
      "Sample entries: [('<PAD>', 0), ('<UNK>', 1), ('a', 2), ('child', 3), ('in', 4), ('pink', 5), ('dress', 6), ('is', 7), ('climbing', 8), ('up', 9)]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert the tokens to integers\n",
   "id": "7af2203e9e98d4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:22:29.854620Z",
     "start_time": "2026-01-05T21:22:29.761750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Creating a variable for unk token index\n",
    "UNK_IDX = word_to_idx[UNK_TOKEN]\n",
    "\n",
    "sequence = []\n",
    "\n",
    "#For loop to check if the word is in the tokens dataframe; if it is just adds the index; if it's not it will add the unk index\n",
    "for tokens in df['tokens']:\n",
    "    seq = []\n",
    "    for word in tokens:\n",
    "        if word in word_to_idx:\n",
    "            seq.append(word_to_idx[word])\n",
    "        else:\n",
    "            seq.append(UNK_IDX)\n",
    "    #Appending to the empty sequence list\n",
    "    sequence.append(seq)\n",
    "\n",
    "print(\"Original: \", df['tokens'][1])\n",
    "print(\"Sequence: \", sequence[1])\n",
    "\n"
   ],
   "id": "d4443c9befb13be4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['a', 'girl', 'going', 'into', 'a', 'wooden', 'building']\n",
      "Sequence:  [2, 16, 17, 18, 2, 19, 20]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Organizing",
   "id": "d93adb039d3f52f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:22:29.876763Z",
     "start_time": "2026-01-05T21:22:29.868312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Dropping caption, and lower_caption columns to organize the dataframe since they aren't useful anymore\n",
    "#Inplace = True to change the original and don't give us just a copy\n",
    "df.drop(['caption', 'lower_caption'], axis= 'columns', inplace= True)\n"
   ],
   "id": "db0b27e6f5175313",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sequence padding and truncating\n",
   "id": "88e4d1da6665dd4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:22:29.991638Z",
     "start_time": "2026-01-05T21:22:29.902091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Checking the biggest sequence and the 95%\n",
    "import numpy as np\n",
    "lengths = [len(i) for i in sequence]\n",
    "print(f\"Max: {max(lengths)}, 95th percentile: {np.percentile(lengths, 95)}\")\n",
    "\n",
    "#Truncating sequences > 20\n",
    "#Padding sequences < 20\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 20\n",
    "\n",
    "padded_sequences = pad_sequences(\n",
    "    sequence,\n",
    "    maxlen = max_length,\n",
    "    #Padding at the end\n",
    "    padding = 'post',\n",
    "    #Truncating at the end\n",
    "    truncating = 'post'\n",
    ")\n",
    "\n",
    "#Printing the first 20 sequences as numpy arrays\n",
    "print(padded_sequences[:20])\n",
    "print(padded_sequences.shape)\n",
    "\n",
    "\n"
   ],
   "id": "ce628a63e60a5910",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 36, 95th percentile: 18.0\n",
      "[[ 2  3  4  2  5  6  7  8  9  2 10 11 12  4 13 14 15  0  0  0]\n",
      " [ 2 16 17 18  2 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 21 16  8 18  2 19 22  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 21 16  8 23 12 24 25 22  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 21 16  4  2  5  6 17 18  2 19 26  0  0  0  0  0  0  0  0]\n",
      " [ 2 27 28 29  2 30 28 31 32  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 27 28 29  2 33 28 34 35 36 37 38 23 39  0  0  0  0  0  0]\n",
      " [ 2 27 28 29  2 40 28 35 41 42 31 43 44 36 37  4 23 45  0  0]\n",
      " [46 47 11 48 49 50 44 36 37 38 23 39  0  0  0  0  0  0  0  0]\n",
      " [46 47 38 51 52 53 36 37  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 21 16 54  4 55 56  4 57 11  2 58 59 35 25 60  4  2 61  0]\n",
      " [ 2 21 16  7 62  4 57 11  2 63 58 59  0  0  0  0  0  0  0  0]\n",
      " [ 2 64 16  4 23 65 66 35 67  4 57 11  2 40 68 35  2 59 38 69]\n",
      " [70  7  2 16 35 71 62  4 57 11  2 59 72  0  0  0  0  0  0  0]\n",
      " [73 16 35 71 72 74  4 23 65  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 75 76 38  2 77 78 79 28 56 80 81  0  0  0  0  0  0  0  0]\n",
      " [ 2 75 76 38 23 77 24 82  2 40 28  7 83 84  0  0  0  0  0  0]\n",
      " [ 2 75 85 38  2 77 74 35  2 40 29 27 28 62 86 24 81  0  0  0]\n",
      " [ 2 87 75 88 38  2 89 77 35 79 28  0  0  0  0  0  0  0  0  0]\n",
      " [75 90 38 77 91 92 11 28 62 38 93  0  0  0  0  0  0  0  0  0]]\n",
      "(40455, 20)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Embedding Layer",
   "id": "e13120cae151f6d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:22:30.369495Z",
     "start_time": "2026-01-05T21:22:30.025277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "\n",
    "#To check the size and length\n",
    "print(f\"Size of the vocabulary: {len(word_to_idx)}\")\n",
    "print(f\"Length of each sequence: {padded_sequences.shape}\")\n",
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "#Default dimension for small / medium datasets (flickr8k)\n",
    "embedding_dim = 128\n",
    "input_length = 20\n",
    "\n",
    "#Building the model\n",
    "model = models.Sequential([\n",
    "    Embedding(input_dim = vocab_size, output_dim = embedding_dim, input_length = input_length), LSTM(256) #Standard default\n",
    "])\n",
    "\n",
    "model.build(input_shape=(None, input_length))\n",
    "model.summary()\n"
   ],
   "id": "845fed4899a7debf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary: 8829\n",
      "Length of each sequence: (40455, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diogo\\Desktop\\Multi-Modal Classification and Analysis of Images and Text using Deep Learning\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001B[38;5;33mEmbedding\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │     \u001B[38;5;34m1,130,112\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │       \u001B[38;5;34m394,240\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,130,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,524,352\u001B[0m (5.81 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,524,352</span> (5.81 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,524,352\u001B[0m (5.81 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,524,352</span> (5.81 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Aligning images with captions",
   "id": "df8dc56f3117d94"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:27:32.838558Z",
     "start_time": "2026-01-05T21:27:31.981761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "\n",
    "#list to store the image path\n",
    "image_paths = []\n",
    "#list to store the tokenized sequence\n",
    "caption_sequences = []\n",
    "\n",
    "IMAGE_DIR = \"../data/images/flickr8k_images/images\"\n",
    "\n",
    "#Looping over rows not images\n",
    "for i in range(len(df)):\n",
    "    #selecting the image file name for the i caption\n",
    "    image_filename = df.iloc[i]['image']\n",
    "    #building  a path so the model can find the image\n",
    "    image_path = os.path.join(IMAGE_DIR, image_filename)\n",
    "\n",
    "    #Adding to the lists image_path per caption\n",
    "    image_paths.append(image_path)\n",
    "    #the padded sequence of that same caption\n",
    "    caption_sequences.append(padded_sequences[i])\n",
    "\n",
    "print(len(image_paths))\n",
    "print(len(caption_sequences))\n",
    "\n",
    "#testing\n",
    "idx = 5\n",
    "print(image_paths[idx])\n",
    "print(caption_sequences[idx])\n",
    "print(df.iloc[idx])\n"
   ],
   "id": "5105adabe0ccdef4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40455\n",
      "40455\n",
      "../data/images/flickr8k_images/images\\1001773457_577c3a7d70.jpg\n",
      "[ 2 27 28 29  2 30 28 31 32  0  0  0  0  0  0  0  0  0  0  0]\n",
      "image                             1001773457_577c3a7d70.jpg\n",
      "tokens    [a, black, dog, and, a, spotted, dog, are, fig...\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
