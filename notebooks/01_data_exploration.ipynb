{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "First we started by reading the csv file 'captions.txt' and then displaying the first five rows",
   "id": "734f616b2ce12d96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:01:35.756092Z",
     "start_time": "2025-12-29T16:01:35.670456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from os import truncate\n",
    "\n",
    "import pandas as pd\n",
    "from keras import Layer\n",
    "from tensorflow.python.keras import Sequential\n",
    "\n",
    "captions_path = \"../data/captions/captions.txt\"\n",
    "\n",
    "df = pd.read_csv(captions_path)\n",
    "print(df.head())\n"
   ],
   "id": "a2ec57dd80d3b095",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       image  \\\n",
      "0  1000268201_693b08cb0e.jpg   \n",
      "1  1000268201_693b08cb0e.jpg   \n",
      "2  1000268201_693b08cb0e.jpg   \n",
      "3  1000268201_693b08cb0e.jpg   \n",
      "4  1000268201_693b08cb0e.jpg   \n",
      "\n",
      "                                             caption  \n",
      "0  A child in a pink dress is climbing up a set o...  \n",
      "1              A girl going into a wooden building .  \n",
      "2   A little girl climbing into a wooden playhouse .  \n",
      "3  A little girl climbing the stairs to her playh...  \n",
      "4  A little girl in a pink dress going into a woo...  \n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we want group all rows that have the same image filename together, keeping only the caption column, then for each group we convert all captions into a python list, and finally convert the pandas object into a dictionary",
   "id": "36954f9ffb154131"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:01:36.070799Z",
     "start_time": "2025-12-29T16:01:35.771529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_to_captions = (\n",
    "    df.groupby('image')['caption'].apply(list).to_dict()\n",
    ")\n",
    "\n",
    "print(\"Number of images: \", len(image_to_captions))"
   ],
   "id": "2557e48b7d4c085e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images:  8091\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating a new column for captions in lower case and without punctuation",
   "id": "d5c12225db9af930"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:01:36.351325Z",
     "start_time": "2025-12-29T16:01:36.082851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import string\n",
    "\n",
    "#Removing the upper cases\n",
    "df['lower_caption'] = df['caption'].str.lower()\n",
    "\n",
    "#Function to remove the punctuation\n",
    "def remove_punctuation(lower_caption):\n",
    "    for char in string.punctuation:\n",
    "        lower_caption = lower_caption.replace(char, '')\n",
    "    return lower_caption\n",
    "\n",
    "df['lower_caption'] = df['lower_caption'].apply(remove_punctuation)\n",
    "\n",
    "#Comparing the new column with the old column\n",
    "df.sample(10)\n",
    "\n"
   ],
   "id": "18b4f84460878908",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           image  \\\n",
       "11488  2565685680_c30972455d.jpg   \n",
       "16832  2914737181_0c8e052da8.jpg   \n",
       "13677  2711075591_f3ee53cfaa.jpg   \n",
       "34196  3679341667_936769fd0c.jpg   \n",
       "4924   2094543127_46d2f1fedf.jpg   \n",
       "12975  2666205903_8d287669e1.jpg   \n",
       "32159   359173181_a75c950aeb.jpg   \n",
       "98      102351840_323e3de834.jpg   \n",
       "30851  3541141771_67d305c873.jpg   \n",
       "1512   1332815795_8eea44375e.jpg   \n",
       "\n",
       "                                                 caption  \\\n",
       "11488  The three black dogs are swimming very close t...   \n",
       "16832               A man waterskis while being pulled .   \n",
       "13677  Two people are scuba diving in blue water with...   \n",
       "34196  Two people kick boxing , with others spectating .   \n",
       "4924   A girl with red hair is sitting on a crocodile...   \n",
       "12975  A child is holding a colorful object and overl...   \n",
       "32159  The brown , furry animal is walking in the sno...   \n",
       "98                  A person standing on a frozen lake .   \n",
       "30851  Two boys , one is climbing a roof , the other ...   \n",
       "1512   A little girl is swinging in a baby swing on t...   \n",
       "\n",
       "                                           lower_caption  \n",
       "11488  the three black dogs are swimming very close t...  \n",
       "16832                a man waterskis while being pulled   \n",
       "13677  two people are scuba diving in blue water with...  \n",
       "34196    two people kick boxing  with others spectating   \n",
       "4924   a girl with red hair is sitting on a crocodile...  \n",
       "12975  a child is holding a colorful object and overl...  \n",
       "32159  the brown  furry animal is walking in the snow...  \n",
       "98                   a person standing on a frozen lake   \n",
       "30851  two boys  one is climbing a roof  the other is...  \n",
       "1512   a little girl is swinging in a baby swing on t...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>lower_caption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11488</th>\n",
       "      <td>2565685680_c30972455d.jpg</td>\n",
       "      <td>The three black dogs are swimming very close t...</td>\n",
       "      <td>the three black dogs are swimming very close t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16832</th>\n",
       "      <td>2914737181_0c8e052da8.jpg</td>\n",
       "      <td>A man waterskis while being pulled .</td>\n",
       "      <td>a man waterskis while being pulled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13677</th>\n",
       "      <td>2711075591_f3ee53cfaa.jpg</td>\n",
       "      <td>Two people are scuba diving in blue water with...</td>\n",
       "      <td>two people are scuba diving in blue water with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34196</th>\n",
       "      <td>3679341667_936769fd0c.jpg</td>\n",
       "      <td>Two people kick boxing , with others spectating .</td>\n",
       "      <td>two people kick boxing  with others spectating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>2094543127_46d2f1fedf.jpg</td>\n",
       "      <td>A girl with red hair is sitting on a crocodile...</td>\n",
       "      <td>a girl with red hair is sitting on a crocodile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>2666205903_8d287669e1.jpg</td>\n",
       "      <td>A child is holding a colorful object and overl...</td>\n",
       "      <td>a child is holding a colorful object and overl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32159</th>\n",
       "      <td>359173181_a75c950aeb.jpg</td>\n",
       "      <td>The brown , furry animal is walking in the sno...</td>\n",
       "      <td>the brown  furry animal is walking in the snow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>102351840_323e3de834.jpg</td>\n",
       "      <td>A person standing on a frozen lake .</td>\n",
       "      <td>a person standing on a frozen lake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30851</th>\n",
       "      <td>3541141771_67d305c873.jpg</td>\n",
       "      <td>Two boys , one is climbing a roof , the other ...</td>\n",
       "      <td>two boys  one is climbing a roof  the other is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>1332815795_8eea44375e.jpg</td>\n",
       "      <td>A little girl is swinging in a baby swing on t...</td>\n",
       "      <td>a little girl is swinging in a baby swing on t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Tokenization for each caption",
   "id": "816fb7649f6a97ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:01:40.330819Z",
     "start_time": "2025-12-29T16:01:36.369530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#Was having trouble with the import word_tokenize so had to add the line below\n",
    "#nltk.download('punkt_tab')\n",
    "\n",
    "#Creating a new column for tokens for each caption\n",
    "df['tokens'] = df['lower_caption'].apply(lambda x: word_tokenize(x))\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "18d1f4ed949c4312",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                       image  \\\n",
       "0  1000268201_693b08cb0e.jpg   \n",
       "1  1000268201_693b08cb0e.jpg   \n",
       "2  1000268201_693b08cb0e.jpg   \n",
       "3  1000268201_693b08cb0e.jpg   \n",
       "4  1000268201_693b08cb0e.jpg   \n",
       "\n",
       "                                             caption  \\\n",
       "0  A child in a pink dress is climbing up a set o...   \n",
       "1              A girl going into a wooden building .   \n",
       "2   A little girl climbing into a wooden playhouse .   \n",
       "3  A little girl climbing the stairs to her playh...   \n",
       "4  A little girl in a pink dress going into a woo...   \n",
       "\n",
       "                                       lower_caption  \\\n",
       "0  a child in a pink dress is climbing up a set o...   \n",
       "1               a girl going into a wooden building    \n",
       "2    a little girl climbing into a wooden playhouse    \n",
       "3  a little girl climbing the stairs to her playh...   \n",
       "4  a little girl in a pink dress going into a woo...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [a, child, in, a, pink, dress, is, climbing, u...  \n",
       "1        [a, girl, going, into, a, wooden, building]  \n",
       "2  [a, little, girl, climbing, into, a, wooden, p...  \n",
       "3  [a, little, girl, climbing, the, stairs, to, h...  \n",
       "4  [a, little, girl, in, a, pink, dress, going, i...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>caption</th>\n",
       "      <th>lower_caption</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A child in a pink dress is climbing up a set o...</td>\n",
       "      <td>a child in a pink dress is climbing up a set o...</td>\n",
       "      <td>[a, child, in, a, pink, dress, is, climbing, u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "      <td>a girl going into a wooden building</td>\n",
       "      <td>[a, girl, going, into, a, wooden, building]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing into a wooden playhouse .</td>\n",
       "      <td>a little girl climbing into a wooden playhouse</td>\n",
       "      <td>[a, little, girl, climbing, into, a, wooden, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl climbing the stairs to her playh...</td>\n",
       "      <td>a little girl climbing the stairs to her playh...</td>\n",
       "      <td>[a, little, girl, climbing, the, stairs, to, h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000268201_693b08cb0e.jpg</td>\n",
       "      <td>A little girl in a pink dress going into a woo...</td>\n",
       "      <td>a little girl in a pink dress going into a woo...</td>\n",
       "      <td>[a, little, girl, in, a, pink, dress, going, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Building the vocabulary",
   "id": "85c2f492de7cb076"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:01:40.480314Z",
     "start_time": "2025-12-29T16:01:40.348440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "#Couting all the words\n",
    "word_counter = Counter()\n",
    "\n",
    "for i in df['tokens']:\n",
    "    word_counter.update(i)\n",
    "\n",
    "#Defining special tokens\n",
    "#To fill empty positions\n",
    "PAD_TOKEN = \"<PAD>\"\n",
    "#When a word is not in the vocabulary\n",
    "UNK_TOKEN = \"<UNK>\"\n",
    "\n",
    "#Creating a vocabulary\n",
    "word_to_idx = {\n",
    "    PAD_TOKEN: 0,\n",
    "    UNK_TOKEN: 1\n",
    "}\n",
    "\n",
    "for word in word_counter:\n",
    "    #Auto increments the ID generator\n",
    "    word_to_idx[word] = len(word_to_idx)\n",
    "\n",
    "\n",
    "print(\"Vocabulary size:\", len(word_to_idx))\n",
    "print(\"Sample entries:\", list(word_to_idx.items())[:10])\n"
   ],
   "id": "f5ab89e550207c45",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8829\n",
      "Sample entries: [('<PAD>', 0), ('<UNK>', 1), ('a', 2), ('child', 3), ('in', 4), ('pink', 5), ('dress', 6), ('is', 7), ('climbing', 8), ('up', 9)]\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Convert the tokens to integers\n",
   "id": "7af2203e9e98d4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:01:40.634616Z",
     "start_time": "2025-12-29T16:01:40.501720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Creating a variable for unk token index\n",
    "UNK_IDX = word_to_idx[UNK_TOKEN]\n",
    "\n",
    "sequence = []\n",
    "\n",
    "#For loop to check if the word is in the tokens dataframe; if it is just adds the index; if it's not it will add the unk index\n",
    "for tokens in df['tokens']:\n",
    "    seq = []\n",
    "    for word in tokens:\n",
    "        if word in word_to_idx:\n",
    "            seq.append(word_to_idx[word])\n",
    "        else:\n",
    "            seq.append(UNK_IDX)\n",
    "    #Appending to the empty sequence list\n",
    "    sequence.append(seq)\n",
    "\n",
    "print(\"Original: \", df['tokens'][1])\n",
    "print(\"Sequence: \", sequence[1])\n",
    "\n"
   ],
   "id": "d4443c9befb13be4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  ['a', 'girl', 'going', 'into', 'a', 'wooden', 'building']\n",
      "Sequence:  [2, 16, 17, 18, 2, 19, 20]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Organizing",
   "id": "d93adb039d3f52f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:01:40.665451Z",
     "start_time": "2025-12-29T16:01:40.652906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Dropping caption, and lower_caption columns to organize the dataframe since they aren't useful anymore\n",
    "#Inplace = True to change the original and don't give us just a copy\n",
    "df.drop(['caption', 'lower_caption'], axis= 'columns', inplace= True)\n"
   ],
   "id": "db0b27e6f5175313",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Sequence padding and truncating\n",
   "id": "88e4d1da6665dd4e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:01:40.810600Z",
     "start_time": "2025-12-29T16:01:40.677932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Checking the biggest sequence and the 95%\n",
    "import numpy as np\n",
    "lengths = [len(i) for i in sequence]\n",
    "print(f\"Max: {max(lengths)}, 95th percentile: {np.percentile(lengths, 95)}\")\n",
    "\n",
    "#Truncating sequences > 20\n",
    "#Padding sequences < 20\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_length = 20\n",
    "\n",
    "padded_sequences = pad_sequences(\n",
    "    sequence,\n",
    "    maxlen = max_length,\n",
    "    #Padding at the end\n",
    "    padding = 'post',\n",
    "    #Truncating at the end\n",
    "    truncating = 'post'\n",
    ")\n",
    "\n",
    "#Printing the first 20 sequences as numpy arrays\n",
    "print(padded_sequences[:20])\n",
    "print(padded_sequences.shape)\n",
    "\n",
    "\n"
   ],
   "id": "ce628a63e60a5910",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 36, 95th percentile: 18.0\n",
      "[[ 2  3  4  2  5  6  7  8  9  2 10 11 12  4 13 14 15  0  0  0]\n",
      " [ 2 16 17 18  2 19 20  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 21 16  8 18  2 19 22  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 21 16  8 23 12 24 25 22  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 21 16  4  2  5  6 17 18  2 19 26  0  0  0  0  0  0  0  0]\n",
      " [ 2 27 28 29  2 30 28 31 32  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 27 28 29  2 33 28 34 35 36 37 38 23 39  0  0  0  0  0  0]\n",
      " [ 2 27 28 29  2 40 28 35 41 42 31 43 44 36 37  4 23 45  0  0]\n",
      " [46 47 11 48 49 50 44 36 37 38 23 39  0  0  0  0  0  0  0  0]\n",
      " [46 47 38 51 52 53 36 37  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 21 16 54  4 55 56  4 57 11  2 58 59 35 25 60  4  2 61  0]\n",
      " [ 2 21 16  7 62  4 57 11  2 63 58 59  0  0  0  0  0  0  0  0]\n",
      " [ 2 64 16  4 23 65 66 35 67  4 57 11  2 40 68 35  2 59 38 69]\n",
      " [70  7  2 16 35 71 62  4 57 11  2 59 72  0  0  0  0  0  0  0]\n",
      " [73 16 35 71 72 74  4 23 65  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 2 75 76 38  2 77 78 79 28 56 80 81  0  0  0  0  0  0  0  0]\n",
      " [ 2 75 76 38 23 77 24 82  2 40 28  7 83 84  0  0  0  0  0  0]\n",
      " [ 2 75 85 38  2 77 74 35  2 40 29 27 28 62 86 24 81  0  0  0]\n",
      " [ 2 87 75 88 38  2 89 77 35 79 28  0  0  0  0  0  0  0  0  0]\n",
      " [75 90 38 77 91 92 11 28 62 38 93  0  0  0  0  0  0  0  0  0]]\n",
      "(40455, 20)\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Embedding Layer",
   "id": "e13120cae151f6d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-29T16:34:19.244259Z",
     "start_time": "2025-12-29T16:34:19.118931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.layers import Embedding, LSTM\n",
    "\n",
    "#To check the size and length\n",
    "print(f\"Size of the vocabulary: {len(word_to_idx)}\")\n",
    "print(f\"Length of each sequence: {padded_sequences.shape}\")\n",
    "\n",
    "vocab_size = len(word_to_idx)\n",
    "#Default dimension for small / medium datasets (flickr8k)\n",
    "embedding_dim = 128\n",
    "input_length = 20\n",
    "\n",
    "#Building the model\n",
    "model = models.Sequential([\n",
    "    Embedding(input_dim = vocab_size, output_dim = embedding_dim, input_length = input_length), LSTM(256) #Standard default\n",
    "])\n",
    "\n",
    "model.build(input_shape=(None, input_length))\n",
    "model.summary()\n"
   ],
   "id": "845fed4899a7debf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary: 8829\n",
      "Length of each sequence: (40455, 20)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_5\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (\u001B[38;5;33mEmbedding\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │     \u001B[38;5;34m1,130,112\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │       \u001B[38;5;34m394,240\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,130,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,524,352\u001B[0m (5.81 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,524,352</span> (5.81 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,524,352\u001B[0m (5.81 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,524,352</span> (5.81 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 59
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
